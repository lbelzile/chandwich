% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/adjust_loglik.R
\name{adjust_loglik}
\alias{adjust_loglik}
\title{Loglikelihood adjustment using the sandwich estimator}
\usage{
adjust_loglik(loglik, ..., cluster = NULL, d = 1, init = rep(0.1, d),
  par_names = NULL, alg_deriv = NULL, alg_hess = NULL)
}
\arguments{
\item{loglik}{A function.  Returns a vector of the
loglikelihood contributions of individual observations.  The first
argument must be the vector of model parameter(s). If any of the model
parameters are out-of-bounds then \code{loglik} should return either
\code{-Inf} or a vector with at least one element equal to \code{-Inf}.}

\item{...}{Further arguments to be passed either to \code{loglik}
(and to \code{alg_deriv} and \code{alg_hess} if these are supplied) or
to \code{\link[stats]{optim}}.  The latter may include \code{gr},
\code{method}, \code{lower}, \code{upper} or \code{control}.
\code{hessian = TRUE} will be used regardless of any value supplied.
The function \code{loglik} must \emph{not} have arguments with names
that match any of these arguments to \code{\link[stats]{optim}}.}

\item{cluster}{A vector or factor indicating from which cluster the
respective loglikelihood contributions from \code{loglik} originate.
Must have the same length as the vector returned by \code{loglik}.
By default each observation is its own cluster.}

\item{d}{A numeric scalar.  The dimension of the parameter vector,
i.e. the number of parameters in the model.}

\item{init}{A numeric vector of initial values for use in the search for
the MLE.  If \code{length(init)} is not equal to \code{d} then
\code{length(init)} is taken as the number of model parameters.}

\item{par_names}{A character vector.  Names of the parameters.}

\item{alg_deriv}{A function with the vector of model parameter(s) as its
first argument.  Returns a \code{length(cluster)} by \code{d} numeric
matrix. Column i contains the derivatives of each of the loglikelihood
contributions in \code{loglik} with respect to model parameter i.}

\item{alg_hess}{A function with the vector of model parameter(s) as its
first argument.  Returns a \code{d} by \code{d} numeric matrix equal to
the Hessian of \code{loglik}, i.e. the matrix of second derivatives of
the function \code{loglik}.}
}
\value{
A function of class \code{"chandwich"} to evaluate an adjusted
  loglikelihood, or the independence loglikelihood, at one or more sets
  of model parameters, with arguments
  \item{x}{A numeric vector or matrix of model parameter values.
    If \code{d = 1} this may be a numeric vector or a matrix with 1 column.
    If \code{d > 1} this may be a numeric vector of length \code{d}
    (one set of model parameters) or a numeric matrix with \code{d}
    columns (\code{ncol(x)} sets of model parameters).}
  \item{adjust}{A logical scalar.  Whether or not to adjust the
    independence loglikelihood.}
  \item{type}{A character scalar.  The type of adjustment to use if
    \code{adjust = TRUE}.  One of \code{"vertical"}, \code{"cholesky"} or
    \code{"dilation"}.}
  The function has (additional) attributes
  \item{d}{The number of models parameters.}
  \item{MLE}{The maximum likelihood estimate.}
  \item{SE}{The unadjusted standard errors.}
  \item{adjSE}{The adjusted standard errors.}
  \item{HI}{The Hessian of the independence loglikelihood.}
  \item{HA}{The Hessian of the adjusted loglikelihood.}
  \item{C_cholesky}{The matrix C in equation (14) of Chandler and Bate
    (2007), calculated using Cholesky decomposition.}
  \item{C_dilation}{The matrix C in equation (14) of Chandler and Bate
    (2007), calculated using spectral decomposition.}
  \item{par_names}{The argument \code{par_names}, if this was supplied.}
}
\description{
Performs adjustments of a user-supplied independence loglikelihood for the
presence of cluster dependence, following
\href{http://dx.doi.org/10.1093/biomet/asm015}{Chandler and Bate (2007)}.
The user provides a function that returns observation-specifc
loglikelihood contributions and a vector that indicates cluster membership.
}
\details{
Three adjustments to the independence loglikelihood are available.
  The `vertical' adjustment is described in Section 6 of
  Chandler and Bate (2007) and two `horizontal' adjustments are described
  in Sections 3.2 to 3.4 of Chandler and Bate (2007).
  See the descriptions of \code{type} and, for the
  horizontal adjustments, the descriptions of \code{C_cholesky} and
  \code{C_dilation}, in \strong{Value}.

  The adjustments involve first and second derviatives of the loglikelihood
  with respect to the model parameters.  These are estimated using
  \code{\link[numDeriv]{jacobian}} and \code{\link[stats]{optimHess}}
  unless \code{alg_deriv} and/or \code{alg_hess} are supplied.
}
\examples{
# Binomial model, rats data ----------

binom_loglik <- function(prob, data) {
  if (prob < 0 || prob > 1) {
    return(-Inf)
  }
  return(dbinom(data[, "y"], data[, "n"], prob, log = TRUE))
}
rat_res <- adjust_loglik(loglik = binom_loglik, data = rats)

x <- seq(0.01, 0.99, by = 0.01)
y1 <- rat_res(x, adjust = FALSE)
y2 <- rat_res(x, type = "vertical")
y3 <- rat_res(x, type = "cholesky")
y4 <- rat_res(x, type = "dilation")
matplot(x, cbind(y1, y2, y3, y4), type = "l", lwd = 2)

# Misspecified Poisson model for negative binomial data ----------
# ... following Section 5.1 of the
"Object-Oriented Computation of Sandwich Estimators" vignette of the
sandwich package
#https://cran.r-project.org/web/packages/sandwich/vignettes/sandwich-OOP.pdf

set.seed(123)
x <- rnorm(250)
y <- rnbinom(250, mu = exp(1 + x), size = 1)
fm_pois <- glm(y ~ x + I(x^2), family = poisson)
adj_fn <- adjust_object(fm_pois)

pois_glm_loglik <- function(pars, y, x) {
  log_mu <- pars[1] + pars[2] * x + pars[3] * x ^ 2
  return(dpois(y, lambda = exp(log_mu), log = TRUE))
}
pois_res <- adjust_loglik(pois_glm_loglik, y = y, x = x, d = 3)

pois_alg_deriv <- function(pars, y, x) {
  mu <- exp(pars[1] + pars[2] * x + pars[3] * x ^ 2)
  return(cbind(y - mu, x * (y - mu), x ^2 * (y - mu)))
}

pois_alg_hess <- function(pars, y, x) {
  mu <- exp(pars[1] + pars[2] * x + pars[3] * x ^ 2)
  alg_hess <- matrix(0, 3, 3)
  alg_hess[1, ] <- -c(sum(mu), sum(x * mu), sum(x ^ 2 * mu))
  alg_hess[2, ] <- -c(sum(x * mu), sum(x ^ 2 * mu), sum(x ^ 3 * mu))
  alg_hess[3, ] <- -c(sum(x ^ 2 * mu), sum(x ^ 3 * mu), sum(x ^ 4 * mu))
  return(alg_hess)
}

pois_res <- adjust_loglik(pois_glm_loglik, y = y, x = x, d = 3,
                          alg_deriv = pois_alg_deriv, alg_hess = pois_alg_hess)


norm_loglik <- function(params, data) {
  mu <- params[1]
  sigma <- params[2]
  if (sigma <= 0) {
    return(-Inf)
  }
  return(dnorm(data, mean = mu, sd = sigma, log = TRUE))
}
mu <- 0
sigma <- 1
norm_data <- rnorm(2000, mean = mu, sd = sigma)
mu_sigma <- c(0, 1)
cluster <- 1:length(norm_data)
cluster <- rep(1:40, 50)

pjn <- adjust_loglik(loglik = norm_loglik, data = norm_data, cluster = cluster,
              init = 0:1)


# GEV model, owtemps data ----------
# ... following Section 5.2 of Chandler and Bate (2007)

if (requireNamespace("revdbayes", quietly = TRUE)) {
  gev_loglik <- function(pars, data) {
    o_pars <- pars[c(1, 3, 5)] + pars[c(2, 4, 6)]
    w_pars <- pars[c(1, 3, 5)] - pars[c(2, 4, 6)]
    o_loglik <- revdbayes::dgev(data[, "Oxford"], o_pars[1], o_pars[2],
                                o_pars[3], log = TRUE)
    w_loglik <- revdbayes::dgev(data[, "Worthing"], w_pars[1], w_pars[2],
                                w_pars[3], log = TRUE)
    return(o_loglik + w_loglik)
  }
}
# Initial estimates (method of moments for the Gumbel case)
sigma <- as.numeric(sqrt(6 * diag(stats::var(owtemps))) / pi)
mu <- as.numeric(colMeans(owtemps) - 0.57722 * sigma)
init <- c(mean(mu), -diff(mu) / 2, mean(sigma), -diff(sigma) / 2, 0, 0)
# Perform the log-likelihood adjustment
ow_res <- adjust_loglik(gev_loglik, data = owtemps, init = init,
          par_names = c("mu0", "mu1", "sigma0", "sigma1", "xi0", "xi1"))
# Rows 1, 3 and 4 of Table 2 of Chandler and Bate (2007)
round(attr(ow_res, "MLE"), 4)
round(attr(ow_res, "SE"), 4)
round(attr(ow_res, "adjSE"), 4)
}
\references{
Chandler, R. E. and Bate, S. (2007). Inference for clustered
  data using the independence loglikelihood. \emph{Biometrika},
  \strong{94}(1), 167-183. \url{http://dx.doi.org/10.1093/biomet/asm015}
}
\seealso{
\code{\link{adjust_object}}: to adjust a fitted model object.

\code{\link{summary.chandwich}} for maximum likelihood estimates
  and unadjusted and adjusted standard errors.

\code{\link{plot.chandwich}} for one- and two- dimensional plots
  of of adjusted loglikelihoods.
}
